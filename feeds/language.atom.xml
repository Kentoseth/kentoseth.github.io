<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Kentoseth - Thoughts on programming, culture, FOSS and more - Language</title><link href="https://kentoseth.github.io/" rel="alternate"></link><link href="https://kentoseth.github.io/feeds/language.atom.xml" rel="self"></link><id>https://kentoseth.github.io/</id><updated>2021-07-28T03:00:00+02:00</updated><subtitle>Coding. Culture. Linux. More.</subtitle><entry><title>Update1: Using OCR, CAT and crowdsourcing to translate Classical Arabic works</title><link href="https://kentoseth.github.io/posts/2021/Jul/28/update1-using-ocr-cat-and-crowdsourcing-to-translate-classical-arabic-works/" rel="alternate"></link><published>2021-07-28T03:00:00+02:00</published><updated>2021-07-28T03:00:00+02:00</updated><author><name>Mohamed H.</name></author><id>tag:kentoseth.github.io,2021-07-28:/posts/2021/Jul/28/update1-using-ocr-cat-and-crowdsourcing-to-translate-classical-arabic-works/</id><summary type="html">&lt;p&gt;An update on using a combination of OCR and CAT software and the power of crowdsourced translations to translate Classical Arabic books&lt;/p&gt;</summary><content type="html">&lt;p&gt;In my last article on &lt;a href="https://kentoseth.tk/posts/2021/jan/12/using-ocr-cat-and-crowdsourcing-to-translate-classical-arabic-works/"&gt;Using OCR, CAT and crowdsourcing to translate Classical Arabic works&lt;/a&gt; I spoke about various tools for digitizing Classical Arabic books and then translating them. Since then I have made a series of discoveries and this update is to document those discoveries.&lt;/p&gt;
&lt;h3&gt;PDFs, OCR and Scanning&lt;/h3&gt;
&lt;p&gt;Going through the process of finding PDF texts and then using OCR to obtain a digital form of the text is laborious. I was fortunate to discover that my idea for digitizing Arabic texts was already thought about in the mid-00s by others. The project name and website is &lt;a href="https://shamela.ws/"&gt;Shamela&lt;/a&gt; and not much will be known to English speakers about it because most Arabic-related discussions happen to be in ... Arabic.&lt;/p&gt;
&lt;p&gt;There is a historical record available &lt;a href="http://kitab-project.org/2020/12/03/al-maktaba-al-shamila-a-short-history/"&gt;here&lt;/a&gt;. Firstly, the history is Shamela is very unclear until today. Based on the link above, the project is founded by an Egyptian and now funded by an &lt;a href="http://www.arrawda.com/"&gt;organization in Saudi Arabia&lt;/a&gt;. The &lt;a href="https://shamela.ws/index.php/page/about-shamela"&gt;about&lt;/a&gt; page does not say much either. Having a historical record of knowing who is creating the digital versions of Classical Arabic works is important for authenticity. While the Quran is well-preserved(Allah has Promised to preserve it), even the Ahadith experienced attempts at fabrication. The attempts at fabrication are what led to compilation efforts like Sahih Bukhari(even though the oral tradition for Hadith is still relied upon to this day). The PDF on the Ar-Rawda website &lt;a href="http://www.arrawdah.com/files/shamela.pdf"&gt;here&lt;/a&gt; provides information about employee names working for Shamela, so we have some basic information. There are 30 people working in the digitizing/verification/data-entry department and 4 programmers working on the software. They all appear to be Egyptians. I will discuss the issue of authenticity a bit more in the next section.&lt;/p&gt;
&lt;p&gt;This leads me to the second point, regarding &lt;a href="http://kitab-project.org/"&gt;KITAB&lt;/a&gt;. KITAB is a project funded by the European Research Council (ERC) and the Aga Khan University(see KITAB homepage). One of their projects is the &lt;a href="https://github.com/OpenITI"&gt;Open Islamicate Texts Initiative (OpenITI)&lt;/a&gt; which is attempting to verify the digital copies provided on Shamela and other collections(Shamela, Shamela-Ibadiyya, Shamela-Shia, Hindawi, Zaydiyya and more). The full list of collections can be found on the &lt;a href="https://github.com/OpenITI"&gt;OpenITI github page&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Book Verifications(and tagging)&lt;/h3&gt;
&lt;p&gt;The way OpenITI does verification is confusing to outsiders. Their &lt;a href="https://docs.google.com/document/d/1twaKWlfiu92pLbFEF5JDRsgo9HQsuOZKSsO4uTjGP_g/edit"&gt;Google Doc&lt;/a&gt; isn't too clear but I was able to gather some basic information from &lt;a href="https://github.com/OpenITI/Annotation/issues/2058"&gt;tickets like these on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also, their documentation is scattered all over the place and concealed within Google Doc links, making them non-indexable to search engines. Even with these drawbacks, their structure for storing books and book metadata is excellent. The structure is broken down like so:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All authors are listed under their date-of-death(Hijri calendar). Example: 0179MalikIbnAnas&lt;/li&gt;
&lt;li&gt;Within each folder, the various books of the author are listed in their folders. Example: 0179MalikIbnAnas.Muwatta + author information stored in a YAML file. Example: 0179MalikIbnAnas.yml&lt;/li&gt;
&lt;li&gt;Within each book folder will be the various books. Their format is like so: date_of_death+author_name+book_name+source+source_URL+language. An example is: 0179MalikIbnAnas.Muwatta.Shamela0001699-ara1 . The source URL is: &lt;a href="https://shamela.ws/index.php/book/1699"&gt;https://shamela.ws/index.php/book/1699&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Each version of the book has its own YAML file. Example: 0179MalikIbnAnas.Muwatta.Shamela0001699-ara1.yml&lt;/li&gt;
&lt;li&gt;Then there is another file called: 0179MalikIbnAnas.Muwatta.yml . This might be some metadata related to the book, but it isn't completely clear&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The process for their tagging/verification seems to follow these steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Finding an online PDF that is the same version as the source-text&lt;/li&gt;
&lt;li&gt;Finding a hard-copy reference of that book on &lt;a href="https://www.worldcat.org"&gt;WorldCat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Doing some text-tagging and annotation for their own flavour of Markdown(which requires a closed-source Windows-only editor to use)&lt;/li&gt;
&lt;li&gt;Reviewing this tagging/annotation&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Authenticity - who checks the scanners?&lt;/h3&gt;
&lt;p&gt;I found the process of verifying the Shamela(and other) books by using digitally-scanned copies of their hard-copy counterparts to be circular. The reason being that the point of failure lies in the anonymous scanners of the hard-copy books.&lt;/p&gt;
&lt;p&gt;Why is this a point of failure?&lt;/p&gt;
&lt;p&gt;To answer this, I provide a series of questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who scanned the book?&lt;/li&gt;
&lt;li&gt;When did the scans take place?&lt;/li&gt;
&lt;li&gt;How certain is it that the claimed scanned version is actually the same as its hard-copy counterpart?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I contacted the Shamela team via email to understand how they digitized books. Perhaps they used hard-copy books and did their own scanning. I asked the following questions to them:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;My query to you is about how you authenticate or verify the books that you are digitizing?&lt;/p&gt;
&lt;p&gt;What method do you follow? Do you keep a digital PDF and a hard copy of each book?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There(rather short) response was:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Yes. In books we digitize, we keep a pdf and text copies. No hard copies here&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I sent a follow-up email querying the hard-copy problem and received the same response as above, albeit in larger font. This all but confirmed that Shamela are also just using scanned copies of books found on the internet and leads me to the next point ...&lt;/p&gt;
&lt;p&gt;The reason the OpenITI team are able to verify books according to version is because the Shamela team are essentially just finding these scanned copies online themselves and then digitizing it. Hence the circular problem. The text and digitally-scanned copy will match, but it doesn't seem like OpenITI or even Shamela are asking: do the digitally-scanned copies match their hard-copy versions?&lt;/p&gt;
&lt;h3&gt;Connecting the physical to the digital&lt;/h3&gt;
&lt;p&gt;While it may be daunting, verifying the hard-copies against the digitally-scanned ones would close the loop on authenticity. The OpenITI team is taking care of making sure there are digitally-scanned copies that match up to the text, what remains is to connect the digitally-scanned copy to its hard-copy counterpart.&lt;/p&gt;
&lt;p&gt;A simple method of verifying(and reaping rewards for practicing the Sunnah) would be to use an &lt;a href="https://hadithanswers.com/the-significance-of-odd-numbers/"&gt;odd number&lt;/a&gt; (&lt;a href="https://www.abuaminaelias.com/dailyhadithonline/2021/05/31/allah-loves-witr/"&gt;other reference&lt;/a&gt; like 3 and finding 3 randomly-chosen points in the text, then comparing these to the digital-scan and then to the hard-copy.&lt;/p&gt;
&lt;p&gt;I initially considered the number 33, but besides tasbih-fatimi, I found no significance to that number specifically(although it is an odd number too).&lt;/p&gt;
&lt;h3&gt;CAT tools - OmegaT, AI/ML and ethics&lt;/h3&gt;
&lt;p&gt;Regarding CAT tools, &lt;a href="https://weblate.org/en/"&gt;Weblate&lt;/a&gt; is not a suitable option. It is geared towards Open Source projects and not books. I spent a lot of(perhaps pointless) time looking at the various CAT tools available.&lt;/p&gt;
&lt;p&gt;I did learn a lot about CAT-related software:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Various types of CAT tools exist, some using only human-driven data and some using a mix of Machine Translations(MT) that are then edited by humans&lt;/li&gt;
&lt;li&gt;Human-driven data is stored in Translation Memories(called TMs), which are also now being used for Machine Learning in something called: &lt;a href="https://site.matecat.com/adaptive-mt-modernmt/"&gt;Adaptive MT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The industry has had its own 'cloud' moment in the form of &lt;a href="https://site.matecat.com/benefits/"&gt;Matecat&lt;/a&gt; and others that followed, which are able to benefit from the massive corpora created by users&lt;/li&gt;
&lt;li&gt;Adding this "Adaptive MT" was something a lot of the proprietary players did to either keep up with the competition or to just add marketing spin to their products(I didn't find any studies to indicate its effectiveness for translators, although it is marketed as such)&lt;/li&gt;
&lt;li&gt;There is some strange and possibly unethical funding model with some of these Open Source projects(which I will discuss below)&lt;/li&gt;
&lt;li&gt;There is only 1 major Open Source tool in comparison to the proprietary ones and it is called: &lt;a href="http://www.omegat.org/"&gt;OmegaT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The situation behind what &lt;em&gt;I would personally consider unethical(and not proven in a court of law)&lt;/em&gt; is the way in which some Open Source projects were funded and how their business models evolved. What I discovered was that both MateCat and ModernMT were partially or fully-funded by the EU and research grants, but these projects evolved into subscription-services. &lt;em&gt;My personal view&lt;/em&gt; is that using research/grant money intended to build out an Open Source product and then 'forking' it into your own paid-for proprietary cloud service once a proven business model exists is somewhat unethical(evidenced by &lt;a href="https://github.com/modernmt/modernmt/issues/580#issuecomment-770790049"&gt;ModernMT's roadmap&lt;/a&gt; that essentially puts the Open Source project into maintenance mode).&lt;/p&gt;
&lt;p&gt;The idea behind Adaptive MT sounds really cool to have for an undertaking like translating Classical Arabic works, but I reasoned that it won't be of much use because there isn't much existing data to train the MT(via TMs or Translation Memories).&lt;/p&gt;
&lt;p&gt;I previously discussed that 1 of the goals of the translation was to crowdsource the effort so that lots of content can be translated simultaneously. The advantages of web-based tools over OmegaT are the minimal install requirements and more polished UIs. On the other hand, offline collaboration becomes possible with software like OmegaT. The &lt;a href="https://omegat.sourceforge.io/manual-standard/en/howtos.html#howto.setupteamproject"&gt;Team Project&lt;/a&gt; also requires a server to be setup, but this would be the case for a web-based tool as well.&lt;/p&gt;
&lt;h3&gt;Creating an umbrella for the different projects&lt;/h3&gt;
&lt;p&gt;I am busy formulating an outline for the different projects and I will place them under an umbrella website. Having a structure is important for being able to know what the goals are and then working towards them with small iterations.&lt;/p&gt;
&lt;p&gt;I will announce the umbrella website name and the structure in the next update.&lt;/p&gt;</content><category term="Language"></category><category term="culture"></category><category term="languages"></category><category term="ideas"></category><category term="OCR"></category><category term="CAT"></category><category term="Arabic"></category></entry><entry><title>Memon(language): Saying you and your</title><link href="https://kentoseth.github.io/posts/2021/Jun/30/memonlanguage-saying-you-and-your/" rel="alternate"></link><published>2021-06-30T02:00:00+02:00</published><updated>2021-06-30T02:00:00+02:00</updated><author><name>Mohamed H.</name></author><id>tag:kentoseth.github.io,2021-06-30:/posts/2021/Jun/30/memonlanguage-saying-you-and-your/</id><summary type="html">&lt;p&gt;Explaining the you/your pronouns used in the Memon language.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Memoni_language"&gt;Memon(or Memoni as some call it), is a verbal language&lt;/a&gt; that has very little written information that documents the rules of the language. This lack of documentation might even extend to the culture and various habits of the Memon people. In a previous &lt;a href="https://kentoseth.tk/posts/2020/oct/10/expanding-blog-scope/"&gt;blog post&lt;/a&gt; I mentioned how I planned to expand the scope of this blog. Today I am proud to present the first article about the Memon language.&lt;/p&gt;
&lt;p&gt;One caveat about my efforts to document Memon is that the verbal tradition diverges from area to area and the different "types of Memons"(basically a reference to which tribe you originate from in India). My reference point(s) for documenting Memon are the people around me who fluently speak the language.&lt;/p&gt;
&lt;p&gt;Today I will discuss the pronouns: you and your&lt;/p&gt;
&lt;h3&gt;Pronouns: you and your&lt;/h3&gt;
&lt;p&gt;"You and your" fall under the category of personal pronouns. I needed a starting point for writing an article about the Memon language, so I chose these 2 pronouns due to the frequency of usage in communication.&lt;/p&gt;
&lt;p&gt;Languages like Arabic have &lt;a href="https://arabicforbeginners.com/topic/personal-pronouns-overview/"&gt;6 different ways&lt;/a&gt; to say 'you' and a further &lt;a href="https://blogs.transparent.com/arabic/arabic-attached-pronouns/"&gt;6 different ways&lt;/a&gt; to say 'your'. Memon is closer to English in this regard, as there are just 2 ways to say 'you' and 4 ways to say 'your' and the you/your words use the same pronoun(see below).&lt;/p&gt;
&lt;h3&gt;Pronoun: you - tu/ain&lt;/h3&gt;
&lt;p&gt;The Memon equivalent of you is: tu or ain&lt;/p&gt;
&lt;p&gt;Both words mean 'you' and they are gender neutral(meaning that tu/ain) can both be used for males or both be used for females.&lt;/p&gt;
&lt;p&gt;Why the different words? This is where Memon gets interesting. 'tu' is used for your peers and people of a similar or younger background. 'ain' is used for your elders. Baked into the language is the idea of respecting older people.&lt;/p&gt;
&lt;p&gt;Pronounciation:&lt;/p&gt;
&lt;p&gt;'Tu' is pronounced like two.&lt;/p&gt;
&lt;p&gt;The 'n' in ain is silent.&lt;/p&gt;
&lt;p&gt;'Ain' is pronounced like eye.&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;p&gt;tu kidaa si aaviye(n)? / ai(n) kidaa si aaviye? - Where did you come from?
Pronounced: two kid-aah see aah-vee-yeh(soft 'h' sound) / eye kid-aah see aah-vee-yeh(soft 'h' sound)&lt;/p&gt;
&lt;h3&gt;Pronoun: your - tojo/toji + ainjo/ainji&lt;/h3&gt;
&lt;p&gt;The pronoun for 'your' gets a bit more tricky and it was harder to understand the context of usage. Here, the 'your' is is divided into male/female:&lt;/p&gt;
&lt;p&gt;tojo/ainjo = male
toji/ainji = female&lt;/p&gt;
&lt;p&gt;My first assumption was that the male/female options were used when speaking to a male or female. But &lt;em&gt;holds breath&lt;/em&gt; ... Memon (possibly) shares some familiarity with Arabic regarding this. The context of when to use 'ji' or 'jo' depends on the words within the sentence or the context(see below for the discussion) and not on the gender of the person you are speaking to. This made me assume(as yet not fully proven) that Memon has masculine and feminine words &lt;a href="https://www.madinaharabic.com/arabic-language-course/lessons/L006_001.html"&gt;just like Arabic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pronounciation:&lt;/p&gt;
&lt;p&gt;'Tojo' - I will split this in 2. 'To' is pronounced like 'shore' but with the silent 'r'. Another way to understand it is the 'shaw' in "Shawshank". The 'jo' in 'tojo'/'ainjo' is pronounced like jaw. A spell-as-you-speak-it way of spelling it would be: tawjaw/eyejaw&lt;/p&gt;
&lt;p&gt;The 'ji' in 'toji' is pronounced like 'bee'&lt;/p&gt;
&lt;p&gt;Examples:&lt;/p&gt;
&lt;p&gt;tojo naalo lak hidaa/ainjo naalo lik hidaa - Write your name here
Pronounced: tawjaw naa-law lak(pronounced like flip) he-daa / eyejaw naa-law lak(pronounced like flip) he-daa&lt;/p&gt;
&lt;h3&gt;Masculine and Feminine&lt;/h3&gt;
&lt;p&gt;Documenting the masculine/feminine will prove tricky. It is not clear whether it is the general context that determines whether to use 'jo' or 'ji' or if certain words are feminine by nature(like Arabic has). I will keep trying to find examples to pick out a pattern(or lack thereof).&lt;/p&gt;
&lt;h3&gt;Next post: Interrogative pronouns&lt;/h3&gt;
&lt;p&gt;In the next blog post, I will discuss the interrogative pronouns like: what, when, where, how and who&lt;/p&gt;
&lt;p&gt;For any mistakes in this article, please email me and I will fix them.&lt;/p&gt;</content><category term="Language"></category><category term="memon"></category><category term="pronouns"></category><category term="you"></category><category term="your"></category></entry><entry><title>Installing INCEpTION - an Open Source tool for Linguistic Annotation</title><link href="https://kentoseth.github.io/posts/2021/Apr/25/installing-inception-an-open-source-tool-for-linguistic-annotation/" rel="alternate"></link><published>2021-04-25T03:00:00+02:00</published><updated>2021-04-25T03:00:00+02:00</updated><author><name>Mohamed H.</name></author><id>tag:kentoseth.github.io,2021-04-25:/posts/2021/Apr/25/installing-inception-an-open-source-tool-for-linguistic-annotation/</id><summary type="html">&lt;p&gt;A guide to install INCEpTION on Linux-based distros&lt;/p&gt;</summary><content type="html">&lt;p&gt;In a previous post about &lt;a href="https://kentoseth.tk/posts/2021/mar/05/tarkeeb-the-concept-of-sentence-analysisor-linguistic-annotation-in-arabic/"&gt;Tarkeeb&lt;/a&gt; I mentioned the use of annotation software for rebuilding the Quran Corpus or building any Arabic corpus. I discussed software like &lt;a href="https://github.com/proycon/flat"&gt;Flat&lt;/a&gt; but then mentioned my preferred option for annotation, &lt;a href="https://inception-project.github.io/"&gt;INCEpTION&lt;/a&gt;. Below I will explain how to install INCEpTION on Ubuntu 20.04(you should be able to adjust the commands to install it on most distros).&lt;/p&gt;
&lt;h3&gt;Installing Java&lt;/h3&gt;
&lt;p&gt;If you use a system container like &lt;a href="https://linuxcontainers.org/"&gt;LXC&lt;/a&gt;, the standard containers don't come with Java installed. This is a good thing, as it allows you to choose &lt;a href="https://adoptopenjdk.net/"&gt;OpenJDK&lt;/a&gt; over Oracle's Java.&lt;/p&gt;
&lt;p&gt;To install OpenJDK, do the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt update
sudo apt upgrade
sudo apt install openjdk-11-jdk
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Verifying that Java is installed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;java --version
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If it didn't work, visit &lt;a href="https://adoptopenjdk.net/installation.html"&gt;here&lt;/a&gt; for debugging.&lt;/p&gt;
&lt;h3&gt;Downloading &amp;amp; Running INCEpTION&lt;/h3&gt;
&lt;p&gt;Create a directory for the standalone Java executable:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkdir annotation/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Download &lt;a href="https://inception-project.github.io/downloads/"&gt;INCEpTION&lt;/a&gt; from here. When I installed the software, it worked with version 0.18.0. However, version 0.19.3 should also work(I will update this article if it doesn't).&lt;/p&gt;
&lt;p&gt;Save the &lt;code&gt;inception-app-webapp-0.19.3-standalone.jar&lt;/code&gt; into the &lt;code&gt;annotation/&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;On the Downloads page above, the instructions for running the web application are:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;java -jar inception-app-webapp-0.19.3-standalone.jar
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These instructions assume that you are running the executable locally and can double-click on it. This didn't work for me because I isolated the app into a container.&lt;/p&gt;
&lt;p&gt;After a bit of yak-shaving, I learned that INCEpTION is built using the &lt;a href="https://spring.io/projects/spring-framework"&gt;Spring Framework&lt;/a&gt;. To run a Spring web application as if it was a remote application and making it accessible outside a container, the following command needs to be used:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;java -Djava.awt.headless=true -Dserver.port=8999 -Dserver.ip=0.0.0.0 -jar inception-app-webapp-0.19.3-standalone.jar
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Binding to &lt;code&gt;0.0.0.0&lt;/code&gt; and a specific port is self-explanatory. I cannot recall why, but running the application as &lt;code&gt;headless&lt;/code&gt; was required to make it work. If you can run it without the &lt;code&gt;headless&lt;/code&gt; command, please email me and explain how/why.&lt;/p&gt;
&lt;h3&gt;Using INCEpTION&lt;/h3&gt;
&lt;p&gt;The application should now be accessible on the container IP on the specific port selected. eg. &lt;code&gt;10.0.4.44:8999&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Thereafter you can look at the &lt;a href="https://inception-project.github.io/releases/0.19.3/docs/user-guide.html"&gt;User Guide&lt;/a&gt; for more information on how to use it.&lt;/p&gt;
&lt;p&gt;I will be adding a future blog post about rebuilding the Quran Corpus with INCEpTION. At the moment I am manually adding some content to the corpus data. This data was added to the existing &lt;a href="https://corpus.quran.com/"&gt;Quran Corpus&lt;/a&gt; and specifically relates to the &lt;a href="https://corpus.quran.com/documentation/dependencygraph.jsp"&gt;Reference Nodes, Hidden Nodes and Empty Nodes&lt;/a&gt;.&lt;/p&gt;</content><category term="Language"></category><category term="annotation-software"></category><category term="inception"></category><category term="quran-corpus"></category></entry><entry><title>The problem with anglicisation of scholar names</title><link href="https://kentoseth.github.io/posts/2021/Mar/06/the-problem-with-anglicisation-of-scholar-names/" rel="alternate"></link><published>2021-03-06T02:00:00+02:00</published><updated>2021-03-06T02:00:00+02:00</updated><author><name>Mohamed H.</name></author><id>tag:kentoseth.github.io,2021-03-06:/posts/2021/Mar/06/the-problem-with-anglicisation-of-scholar-names/</id><summary type="html">&lt;p&gt;Discussing the drawbacks of anglicisation and why a standard would be good&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you have an interest in early Middle Eastern history or Islamic history, you will come across lots of names of renowned people who shaped history during their time on earth.&lt;/p&gt;
&lt;p&gt;In a previous article, I listed the &lt;a href="https://kentoseth.tk/posts/2021/feb/19/lists-of-scholars-who-learned-from-each-other/"&gt;names of early Islamic scholars who learned from each other&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I copied the names from a book verbatim. As an unaware reader, you might assume this is the only way that these names are spelled. However, this is definitely not the case.&lt;/p&gt;
&lt;p&gt;Anglicisation is defined from &lt;a href="https://en.wikipedia.org/wiki/Anglicisation"&gt;Wikipedia&lt;/a&gt; as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Linguistic anglicisation (or anglicization, occasionally anglification, anglifying, or Englishing) is the practice of modifying foreign words, names, and phrases to make them easier to spell, pronounce, or understand in English.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are some efforts at standardizing found here &lt;a href="https://en.wikipedia.org/wiki/Romanization_of_Arabic"&gt;Romanization of Arabic&lt;/a&gt; but this is just a letter-to-letter matching of Arabic-English and does not cover an actual standard.&lt;/p&gt;
&lt;h3&gt;What does a standard mean?&lt;/h3&gt;
&lt;p&gt;Here is a simple example:&lt;/p&gt;
&lt;p&gt;Is it Abu Haneefa, Abu Hanifa, Aboo Haneefa or Aboo Hanifa? (ra)&lt;/p&gt;
&lt;p&gt;While 'Abu' is self-standardized, Haneefa is not.&lt;/p&gt;
&lt;p&gt;Here is another example. A famous scholar had the name: Wakee bin Jarraa(ra). According to Wikipedia, his page title is &lt;a href="https://en.wikipedia.org/wiki/Waki_ibn_al-Jarrah"&gt;Waki ibn al-Jarrah&lt;/a&gt;, his introductory name is Abū Sufyān Wakīʿ ibn al-Jarrāḥ ibn Malīḥ al-Ruʾāsī al-Kilābī al-Kufī (the part we are looking for is: Wakīʿ ibn al-Jarrāḥ) and the Arabic is وكيع بن الجرّاح&lt;/p&gt;
&lt;h3&gt;Is this even a problem?&lt;/h3&gt;
&lt;p&gt;You may be asking yourself why this even matters? For academics and even people just casually browsing, it matters for many reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A different spelling could link to a completely different individual&lt;/li&gt;
&lt;li&gt;Different spellings not correctly linking to websites that have relevant information(would Waki ibn al-Jarrah give more results than Wakee bin Jarraa or the other way around?)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why does the problem exist?&lt;/h3&gt;
&lt;p&gt;My theory is that it is because of a lack of standard, different people spell out Arabic words according to how they hear it(differently), Arabic-English does not have a clear 1-1 for many letters and the addition of diacritics impacts the different spelling options too.&lt;/p&gt;
&lt;p&gt;How would ح be spelled in English? If the answer is simple and is: 'ha' let's make it more challenging. How would حَ or حَا be spelled?&lt;/p&gt;
&lt;p&gt;Following the Romanization linked to above, a few other issues creep up like the usage of symbols on the English words: wāw/ṣād or capitalization of certain letters to differentiate(ح = Ha and ه = ha). None of these can work in the real world because nobody will follow the conventions of where to capitalize and even fewer people will use the symbols to spell in English.&lt;/p&gt;
&lt;h3&gt;Towards a standard?&lt;/h3&gt;
&lt;p&gt;I don't actually have a solution. Programmers know all about standards too, see below:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Standards" src="https://imgs.xkcd.com/comics/standards.png"&gt;&lt;/p&gt;
&lt;p&gt;For Arabic speakers, this isn't necessary because there is only 1 spelling(I'll exclude the fact that sometimes different Arabs assign different titles to famous scholars). For everyone else, some type of standard should exist that at least conforms to an Arabic-English of names(the standard could apply to all Arabic names or just the famous scholars).&lt;/p&gt;
&lt;p&gt;This isn't a technical challenge though. I can quickly develop my own solution of what a standard should look like, but adoption and cooperation is more important than solutions. Cooperation between Arabic-speaking countries and non-Arabic speaking countries could lead to some standard. Academics should also be encouraged to adopt the standard, which could be made simpler through online spell-checkers and Arabic-English transliteration tools.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;While I don't expect anything to come of this, I felt it worthwhile to discuss the matter as I morph into a language-geek.&lt;/p&gt;
&lt;p&gt;Yours truly, كنطوسث&lt;/p&gt;</content><category term="Language"></category><category term="scholars"></category><category term="names"></category><category term="arabic"></category><category term="english"></category></entry><entry><title>Tarkeeb - the concept of sentence analysis(or Linguistic Annotation) in Arabic</title><link href="https://kentoseth.github.io/posts/2021/Mar/05/tarkeeb-the-concept-of-sentence-analysisor-linguistic-annotation-in-arabic/" rel="alternate"></link><published>2021-03-05T03:00:00+02:00</published><updated>2021-03-05T03:00:00+02:00</updated><author><name>Mohamed H.</name></author><id>tag:kentoseth.github.io,2021-03-05:/posts/2021/Mar/05/tarkeeb-the-concept-of-sentence-analysisor-linguistic-annotation-in-arabic/</id><summary type="html">&lt;p&gt;Discussing tarkeeb and annotation-software that can be used for it&lt;/p&gt;</summary><content type="html">&lt;p&gt;During my time studying intermediate Arabic, mainly the study of Al-Ajurumiyah[1] in Arabic grammar, I was introduced to the word 'Tarkeeb'. I was initially trying to grasp the concept of what Tarkeeb means, among the mountain of Arabic terms used for different concepts in the language(parts-of-speech, grammatical concepts, morphological concepts and more), until I realized that I have already been exposed to Tarkeeb via &lt;a href="https://corpus.quran.com/"&gt;The Quran Corpus&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Defining Tarkeeb&lt;/h3&gt;
&lt;p&gt;Tarkeeb is basically the equivalent of what is shown in the &lt;a href="https://corpus.quran.com/treebank.jsp"&gt;Quran Corpus Treebank&lt;/a&gt;. I did find a definition from a PDF(the PDF is the only definition or discussion of 'Tarkeeb' I found on the internet that relates to the concept of Linguistic Annotation. I have also removed the link to the PDF for various reasons) but I will copy/paste the definition due to the lack of preservation of digitized works among the many hundreds of Islamic/Arabic websites that depend on 3rd-party services(like the hosted sites on wordpress.com) that get shut down after a few years for various reasons.&lt;/p&gt;
&lt;p&gt;The definition says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tarkeeb,  in  the  English  language,  could  be  best  translated  as  “Sentence Parsing”; though, to explain the concept of it to an English speaker may prove difficult,as neither does English nor –to the best of our knowledge –any other language havesuch a component as “Tarkeeb”. That is, the critical analysis of speech  and  text;  breaking itdown  sentence  by  sentence,  and  analysing  those sentences,  analysing  each  and  every  word  in  the  sentence, tracing  them  back to their root forms, understanding each and every word individually, its role in the  sentence,  why  it  was  inserted,  what  effect  it  has  on  the  word(s)  before  it and the word(s) after it, and thereafter joining that sentence together, piece by piece, like a jigsaw puzzle, after having dissected and fully understood it.&lt;/p&gt;
&lt;p&gt;English does have what they refer to as “Sentence Parsing”, but this can never be compared with “Tarkeeb” in Arabic.Also, “sentence parsing”, as a subject taught formally in schools died out a long time ago. And again, that is besides the  fact  that  Tarkeeb  is  incomparably  more  advanced  and  sophisticated  as compared  to  “Sentence  Parsing”  in  English.  Nevertheless,  English  speakers whohad  studied  sentence  parsing  should  then  at  least  have  a  vague  idea  of what Tarkeeb is about.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The reason the author mentions the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;as neither does English nor –to the best of our knowledge –any other language havesuch a component as “Tarkeeb”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Is due to a drawback in how this field is itself defined. A layperson would not be able to explain the idea behind what Tarkeeb is without digging deeply into the academic areas of language. I happened to do so myself and uncovered that the equivalent of Tarkeeb in other languages is: &lt;a href="https://en.wikipedia.org/wiki/Text_annotation#Linguistic_annotation"&gt;Linguistic annotation&lt;/a&gt;. The field is so broad that there is even a generalized framework for Linguistic Annotation called &lt;a href="https://universaldependencies.org/"&gt;Universal Dependencies&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here is the explanation of UD:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Universal Dependencies (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;How I discovered Linguistic Annotation&lt;/h3&gt;
&lt;p&gt;As I progress in my learning of Classical Arabic, the geek in me has been exploring various software related to different areas of language(and Arabic). Contrary to what the Quran Corpus offers on its &lt;a href="https://corpus.quran.com/java/download.jsp"&gt;download page&lt;/a&gt;, it is very much a closed-source project that cannot be hosted locally. I wanted to host my own instance of the software in order to experiment with applying Linguistic Annotation to other Islamic texts like Hadith(a future full article will be dedicated to explaining this fully). Through a major yak-shave, I uncovered both a more accurate definition(see below) and label for the concept(Linguistic Annotation) and a bunch of &lt;a href="https://corpus-analysis.com/"&gt;Tools for Corpus Linguistics&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;A clearer definition Tarkeeb&lt;/h3&gt;
&lt;p&gt;Tarkeeb would basically be:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The annotation of the(textual) Arabic language with various concepts related to understanding language(like parts-of-speech, morphological features and dependency-graphs)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A picture is worth a thousand words, so here is a borrowed image from the Quran Corpus:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Surah Ikhlas" src="https://kentoseth.github.io/images/tarkeeb/corpus-image.png"&gt;&lt;/p&gt;
&lt;p&gt;My definition is probably inaccurate to academic-linguists, but for laypeople it is easier to understand. Case in point is the Wikipedia explanation(linked above), which is too burdensome for laypeople to understand without having to know the various domain-specific definitions that only academic-linguists would.&lt;/p&gt;
&lt;h3&gt;Annotation software&lt;/h3&gt;
&lt;p&gt;I shared a link above to various Open Source &lt;a href="https://corpus-analysis.com/"&gt;Corpus Linguistics tools&lt;/a&gt;, but the ones that would be best suited for Tarkeeb are the annotation ones. I tried a few of them that were closest to what the Quran Corpus has in structure, like &lt;a href="https://github.com/proycon/flat"&gt;Flat&lt;/a&gt;. I was biased towards Python options as those would be the easiest for me to modify if I needed code-modifications. After some deeper investigation I found &lt;a href="https://inception-project.github.io/"&gt;INCEpTION&lt;/a&gt; via &lt;a href="https://webanno.github.io/webanno/"&gt;WebAnno&lt;/a&gt;. INCEpTION is really amazing and has practically everything I need for a possible clone of the Quran Corpus. In a future article I will discuss how to install and run INCEpTION locally.&lt;/p&gt;
&lt;p&gt;Many of the advanced Open Source language-annotation projects are written in Java. The complexity of some of these projects is profound and I have a new-found respect for the often-derided language(which I am still not a fan of due to its C-like syntax and difficulty to grasp when compared to Python).&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;If you have any thoughts on Tarkeeb, learning Arabic, Open Source software(related to what I discussed above), drop me an email and we can share our thoughts on the subject.&lt;/p&gt;
&lt;p&gt;[1] Al-Ajurumiyah is a famous Arabic Grammar book written by Abu `Abdillah Muḥammad b. Muḥammad b. Dāwūd as-Sinhājī&lt;/p&gt;</content><category term="Language"></category><category term="Arabic"></category><category term="NLP"></category><category term="languages"></category><category term="annotation-software"></category></entry><entry><title>Using OCR, CAT and crowdsourcing to translate Classical Arabic works</title><link href="https://kentoseth.github.io/posts/2021/Jan/12/using-ocr-cat-and-crowdsourcing-to-translate-classical-arabic-works/" rel="alternate"></link><published>2021-01-12T03:00:00+02:00</published><updated>2021-01-12T03:00:00+02:00</updated><author><name>Mohamed H.</name></author><id>tag:kentoseth.github.io,2021-01-12:/posts/2021/Jan/12/using-ocr-cat-and-crowdsourcing-to-translate-classical-arabic-works/</id><summary type="html">&lt;p&gt;Using a combination of OCR and CAT software and the power of crowdsourced translations to translate Classical Arabic books&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was recently exploring the idea of how to convert Classical Arabic/Islamic works into English using a combination of CAT(Computer Assisted Translation), OCR(Optical Character Recognition) and crowdsourcing students in Arabic studies. The lazy answer for wanting to translate books is to use a combination of OCR and MT(machine-translation) tools(Google/Bing translator) to get an Arabic-to-English translation. This does not work for a few reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Machine-translation is not as good as human translation as explained &lt;a href="https://www.cmmlanguages.com/cat-tools-vs-machine-translation.html"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Machine-translation is capable of converting MSA Arabic sentences somewhat accurately, but many Islamic words are not covered by the existing MT tools and will not be accurate for basic sentences.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Below I will discuss the existing challenges and then present my theoretical solution.&lt;/p&gt;
&lt;h3&gt;The Challenges&lt;/h3&gt;
&lt;p&gt;Although there are many translations of famous works(like the Quran and the 6 Hadith books), there are also lots of other niche works that are not translated to English. The second shortcoming is that copyright is not strictly respected and many PDF documents are floating around of various Arabic-English translations that presumably do not have the permission of the respective authors. The lack of respect for copyright is a negative for expert translators who spend many thousands of hours going through volumes of a single work and charge a fair price for their translations. These works are then scanned/uploaded without their permission and they lose valuable income that could enable them to create more translations.&lt;/p&gt;
&lt;p&gt;Thirdly, many existing translations are only available in physical(printed) books. No digital copies, APIs or even copyable texts exist for many translated works beyond the Quran/Hadith. Some PDF readers are able to copy the English text(even though these are scanned versions of the physical books) but attempting to copy the Arabic text results in malformed text appearing(likely due to left-to-right copying of the text while Arabic is a right-to-left language).&lt;/p&gt;
&lt;p&gt;Lastly, the economics of translating niche works does not make many of them feasible for expert translators. A simple example might be a work like &lt;a href="https://en.wikipedia.org/wiki/Muhammad_al-Shaybani#Works"&gt;al-Jami al-Saghir&lt;/a&gt; by Imam Muhammad al-Shaybani. A niche book like this might only appeal to advanced students of Islamic knowledge within the Hanafi school of jurisprudence.&lt;/p&gt;
&lt;h3&gt;Outlining the Steps&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Sourcing PDF versions of Arabic-only Classical works - this will not affect copyright(to the best of my knowledge) as most of the authors lived 1000+ years ago and many of the printed works are just reprints, so even old editions will work&lt;/li&gt;
&lt;li&gt;Choosing a source-material for the Translation-Memory of the CAT tool - in this case I think that the Arabic-English from the Hadith books will be the optimal solution.&lt;/li&gt;
&lt;li&gt;Appealing to students of Arabic studies to participate in crowdsourcing the translations - this is a win-win as it helps them improve their Arabic translation skills&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;The Solution&lt;/h3&gt;
&lt;p&gt;The following is my algorithm for how to achieve the desired outcome. I will mention the software I propose to use in each step below.&lt;/p&gt;
&lt;h4&gt;PDFs and Scanning - OCR&lt;/h4&gt;
&lt;p&gt;In order to make the text copyable from PDFs, I propose using 2 pieces of software:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/tesseract-ocr/tesseract"&gt;Tesseract&lt;/a&gt; - this will be the engine that will read the text. Training data can be sourced from &lt;a href="https://github.com/tesseract-ocr/tessdata_best"&gt;here&lt;/a&gt; for Arabic&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/writecrow/ocr2text"&gt;PDF to TXT (with OCR)&lt;/a&gt; - this is the only listed option for PDF-to-text built on top of Tesseract. Using this script on top of the OCR engine will enable scanning of the sourced PDFs&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Translation Management - CAT&lt;/h4&gt;
&lt;p&gt;The best translation management tool with multi-user support I found is &lt;a href="https://weblate.org/en/"&gt;Weblate&lt;/a&gt;. It is the best because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is used by 1000+ other projects for translations&lt;/li&gt;
&lt;li&gt;It has multi-user support&lt;/li&gt;
&lt;li&gt;It has built-in version-control&lt;/li&gt;
&lt;li&gt;It has Translation Memory support&lt;/li&gt;
&lt;li&gt;It is popular on GitHub(the most Stars)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The source material for the Translation Memory can be obtained from the sunnah.com &lt;a href="https://sunnah.api-docs.io/"&gt;API&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once the data is loaded into the Translation Memory, this can be applied app-wide and various students can use the CAT tool to translate pieces of content much faster and the content can also be reviewed by others before being approved.&lt;/p&gt;
&lt;h4&gt;Books, Authors and Works&lt;/h4&gt;
&lt;p&gt;A starting list of books I found is here: &lt;a href="https://en.wikipedia.org/wiki/List_of_Sunni_books"&gt;List of Sunni books&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This can be a starting point for sourcing/finding various books to translate.&lt;/p&gt;
&lt;p&gt;There should be some type of standard for approving which books are to be crowdsourced as translations. I do not have such a standard as of yet but it can be developed as time goes by.&lt;/p&gt;
&lt;h4&gt;The Goals&lt;/h4&gt;
&lt;p&gt;The first and primary goal for such a task is to Obtain the Pleasure of God. Although we might shy away from admitting it on technical/personal blogs, deep inside a person's heart, this is always the main goal.&lt;/p&gt;
&lt;p&gt;Another important goal for me is to document and develop a system where both the content and the technology behind it is Open Source and accessible to all. I would likely propose that all the crowdsourced translations have a permissive license like the Wikipedia content license so that the translated works are accessible to all(and any edits and improvements can be made via the system that is accessible to students pursuing Arabic studies).&lt;/p&gt;</content><category term="Language"></category><category term="culture"></category><category term="languages"></category><category term="ideas"></category><category term="OCR"></category><category term="CAT"></category><category term="Arabic"></category></entry></feed>